{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db677ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e920e1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "\n",
      "Found 69600 images belonging to 29 classes.\n",
      "Validation:\n",
      "\n",
      "Found 8700 images belonging to 29 classes.\n",
      "Test:\n",
      "\n",
      "Found 8700 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "target_size = (150, 150)\n",
    "input_shape = (target_size[0], target_size[1], 3)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range = 5,\n",
    "    brightness_range = (0.5,1),\n",
    "    shear_range = 5,\n",
    "    preprocessing_function=tf.image.rgb_to_grayscale\n",
    ")\n",
    "\n",
    "print(\"Training:\\n\")\n",
    "traingen = datagen.flow_from_directory(\n",
    "    directory = \"datasets/asl_alphabet/train\",\n",
    "    target_size = target_size,\n",
    "    seed = 1337\n",
    ")\n",
    "\n",
    "print(\"Validation:\\n\")\n",
    "valgen = datagen.flow_from_directory(\n",
    "    directory = \"datasets/asl_alphabet/val\",\n",
    "    target_size = target_size,\n",
    "    seed = 1337\n",
    ")\n",
    "\n",
    "print(\"Test:\\n\")\n",
    "testgen = datagen.flow_from_directory(\n",
    "    directory = \"datasets/asl_alphabet/test\",\n",
    "    target_size = target_size,\n",
    "    seed = 1337\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19f99f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "cnn.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\" , activation=\"relu\", input_shape=input_shape))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Conv2D(filters=64, kernel_size=(2, 2), padding=\"same\" , activation=\"relu\", input_shape=input_shape))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(units = 256, activation = \"relu\"))\n",
    "\n",
    "cnn.add(Dense(units = 29, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03549f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 87616)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               22429952  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 29)                7453      \n",
      "=================================================================\n",
      "Total params: 22,446,557\n",
      "Trainable params: 22,446,557\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.compile(\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    optimizer = \"adam\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c136b1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No mapping between account names and security IDs was done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! takeown /r /f logs 1>nul\n",
    "! cacls logs /c /G \"ADMINNAME\":F /T 1>nul\n",
    "! del /f /s /q logs 1>nul\n",
    "! rmdir /s /q logs 1>nul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49422d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c81241c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d0d9457ad312a889\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d0d9457ad312a889\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a40169ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "   1/2175 [..............................] - ETA: 0s - loss: 3.3182 - accuracy: 0.0312WARNING:tensorflow:From C:\\Users\\yanco\\.conda\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "2175/2175 [==============================] - 1482s 681ms/step - loss: 1.5098 - accuracy: 0.5455 - val_loss: 0.6325 - val_accuracy: 0.7955\n",
      "Epoch 2/18\n",
      "2175/2175 [==============================] - 1408s 648ms/step - loss: 0.4423 - accuracy: 0.8544 - val_loss: 0.3042 - val_accuracy: 0.9003\n",
      "Epoch 3/18\n",
      "2175/2175 [==============================] - 1437s 661ms/step - loss: 0.2610 - accuracy: 0.9130 - val_loss: 0.2601 - val_accuracy: 0.9130\n",
      "Epoch 4/18\n",
      "2175/2175 [==============================] - 1426s 655ms/step - loss: 0.1823 - accuracy: 0.9399 - val_loss: 0.2190 - val_accuracy: 0.9257\n",
      "Epoch 5/18\n",
      "2175/2175 [==============================] - 1420s 653ms/step - loss: 0.1392 - accuracy: 0.9544 - val_loss: 0.1598 - val_accuracy: 0.9490\n",
      "Epoch 6/18\n",
      "2175/2175 [==============================] - 1425s 655ms/step - loss: 0.1173 - accuracy: 0.9617 - val_loss: 0.1149 - val_accuracy: 0.9624\n",
      "Epoch 7/18\n",
      "2175/2175 [==============================] - 1418s 652ms/step - loss: 0.0986 - accuracy: 0.9685 - val_loss: 0.0928 - val_accuracy: 0.9718\n",
      "Epoch 8/18\n",
      "2175/2175 [==============================] - 1416s 651ms/step - loss: 0.0789 - accuracy: 0.9747 - val_loss: 0.0873 - val_accuracy: 0.9718\n",
      "Epoch 9/18\n",
      "2175/2175 [==============================] - 1422s 654ms/step - loss: 0.0746 - accuracy: 0.9757 - val_loss: 0.1095 - val_accuracy: 0.9657\n",
      "Epoch 10/18\n",
      "2175/2175 [==============================] - 1416s 651ms/step - loss: 0.0612 - accuracy: 0.9809 - val_loss: 0.1447 - val_accuracy: 0.9569\n",
      "Epoch 11/18\n",
      "2175/2175 [==============================] - 1417s 652ms/step - loss: 0.0575 - accuracy: 0.9821 - val_loss: 0.1139 - val_accuracy: 0.9624\n",
      "Epoch 12/18\n",
      "2175/2175 [==============================] - 1429s 657ms/step - loss: 0.0527 - accuracy: 0.9827 - val_loss: 0.0892 - val_accuracy: 0.9733\n",
      "Epoch 13/18\n",
      "2175/2175 [==============================] - 1420s 653ms/step - loss: 0.0479 - accuracy: 0.9849 - val_loss: 0.0963 - val_accuracy: 0.9699\n",
      "Epoch 14/18\n",
      "2175/2175 [==============================] - 1415s 651ms/step - loss: 0.0467 - accuracy: 0.9851 - val_loss: 0.0741 - val_accuracy: 0.9785\n",
      "Epoch 15/18\n",
      "2175/2175 [==============================] - 1414s 650ms/step - loss: 0.0437 - accuracy: 0.9860 - val_loss: 0.0882 - val_accuracy: 0.9739\n",
      "Epoch 16/18\n",
      "2175/2175 [==============================] - 1415s 651ms/step - loss: 0.0387 - accuracy: 0.9875 - val_loss: 0.0740 - val_accuracy: 0.9792\n",
      "Epoch 17/18\n",
      "2175/2175 [==============================] - 1416s 651ms/step - loss: 0.0373 - accuracy: 0.9883 - val_loss: 0.0901 - val_accuracy: 0.9762\n",
      "Epoch 18/18\n",
      "2175/2175 [==============================] - 1416s 651ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.0926 - val_accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "mcp_save = ModelCheckpoint(\"simple_cnn.h5\", save_best_only=True, monitor=\"accuracy\", mode=\"max\")\n",
    "\n",
    "history = cnn.fit(\n",
    "    traingen,\n",
    "    epochs = 18,\n",
    "    validation_data = valgen,\n",
    "    callbacks=[mcp_save, tensorboard_callback]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
